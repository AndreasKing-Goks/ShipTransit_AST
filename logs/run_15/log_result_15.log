-------------------------------------------------------- STRESS TEST PARAMETERS ---------------------------------------------------------
* Coefficient and boolean parameters
 Policy type                                   : Gaussian
 Do evaluation                                 : True
 Reward discount factor (gamma)                : 0.99
 Target smoothing coefficient (tau)            : 0.005
 Action sampling frequency coefficient (theta) : 2
 Maximum action sampling count per episode     : 7
 RL learning rate                              : 0.0003
 SAC's entropy temperature parameters (alpha)  : 0.2
 Do automatic entroypy tuning                  : True

* Neural networks parameters
 Set random seed                               : 25450
 SAC batch size                                : 64
 SAC replay size                               : 1000
 SAC hidden network size                       : 256
 Run training on CUDA                          : True

* Timesteps and episode parameters
 Simulator time step size                      : 0.5
 Maximum steps count over all episodes         : 100000
 Steps count for initial exploration           : 10000
 Steps count for model update                  : 1
 Steps count for target update                 : 1
 Episodes count for evaluation                 : 20
 Episodes count during evaluation              : 20

* Others
 Autopilot LOS's radius of acceptance          : 300
 Autopilot LOS's lookahead distance            : 1000

------------------------------------------------------------ TRAINING PHASE -------------------------------------------------------------

Episode: 1   , Elapsed time (s):2.7, Total numsteps: 3640  , Episode steps: 3641 , Travel distanced: 0.00  , Travel time: 1820.00 Reward: -1690.18
Status:|Route point is sampled in terminal state|
New best policy saved at Episode 1 with Reward: -1690.18
Episode: 2   , Elapsed time (s):0.6, Total numsteps: 4515  , Episode steps: 876  , Travel distanced: 0.00  , Travel time: 437.50 Reward: -2274.87
Status:|Route point is sampled in terminal state|
Episode: 3   , Elapsed time (s):2.6, Total numsteps: 8026  , Episode steps: 3512 , Travel distanced: 0.00  , Travel time: 1755.50 Reward: -1468.05
Status:|Route point is sampled in terminal state|
New best policy saved at Episode 3 with Reward: -1468.05
Episode: 4   , Elapsed time (s):1.2, Total numsteps: 9581  , Episode steps: 1556 , Travel distanced: 0.00  , Travel time: 777.50 Reward: 1113.27 
Status:|Collision failure|
New best policy saved at Episode 4 with Reward: 1113.27
Episode: 5   , Elapsed time (s):0.2, Total numsteps: 9860  , Episode steps: 280  , Travel distanced: 0.00  , Travel time: 139.50 Reward: 772.73  
Status:|Map horizon hit failure|
Episode: 6   , Elapsed time (s):4.0, Total numsteps: 15146 , Episode steps: 5287 , Travel distanced: 0.00  , Travel time: 2643.00 Reward: -427.71 
Status:|Route point is sampled in terminal state|
Episode: 7   , Elapsed time (s):3.9, Total numsteps: 20653 , Episode steps: 5508 , Travel distanced: 0.00  , Travel time: 2753.50 Reward: -617.83 
Status:|Route point is sampled in terminal state|
Episode: 8   , Elapsed time (s):0.2, Total numsteps: 20876 , Episode steps: 224  , Travel distanced: 0.00  , Travel time: 111.50 Reward: 757.55  
Status:|Map horizon hit failure|
Episode: 9   , Elapsed time (s):0.1, Total numsteps: 21069 , Episode steps: 194  , Travel distanced: 0.00  , Travel time: 96.50 Reward: 750.30  
Status:|Map horizon hit failure|
Episode: 10  , Elapsed time (s):3.9, Total numsteps: 26479 , Episode steps: 5411 , Travel distanced: 0.00  , Travel time: 2705.00 Reward: -480.38 
Status:|Route point is sampled in terminal state|
